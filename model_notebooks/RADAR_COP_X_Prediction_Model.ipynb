{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m Model\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m \u001b[39mimport\u001b[39;00m Input, Conv3D, Flatten, Dense, LSTM, TimeDistributed, Reshape\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.keras'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv3D, Flatten, Dense, LSTM, TimeDistributed, Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base paths for force plate (FP) and RADAR data\n",
    "base_path_fp = '/Volumes/FourTBLaCie/Yoga_Study_FP_FUFD'\n",
    "base_path_radar = '/Volumes/FourTBLaCie/Yoga_Study_RADAR_4Ch_FUFD'\n",
    "\n",
    "# Assume we're dealing with the '01' subfolder as in the uploaded image example\n",
    "subfolder = '01'\n",
    "\n",
    "# Construct the full paths for the subfolders\n",
    "full_path_fp = os.path.join(base_path_fp, subfolder)\n",
    "full_path_radar = os.path.join(base_path_radar, subfolder)\n",
    "\n",
    "# Get the list of files in each subfolder\n",
    "files_fp = [f for f in os.listdir(full_path_fp) if f.endswith('.npy')]\n",
    "files_radar = [f for f in os.listdir(full_path_radar) if f.endswith('.npy')]\n",
    "\n",
    "# Match files by name (without the extension and the last part after underscore)\n",
    "matched_files = [(fp, radar) for fp in files_fp for radar in files_radar if fp.split('_')[0] == radar.split('_')[0]]\n",
    "\n",
    "# Load the data and create pairs\n",
    "data_pairs = []\n",
    "for fp, radar in matched_files:\n",
    "    fp_data = np.load(os.path.join(full_path_fp, fp))\n",
    "    radar_data = np.load(os.path.join(full_path_radar, radar))\n",
    "    data_pairs.append((radar_data, fp_data))\n",
    "\n",
    "# Now, you have a list of tuples where each tuple is a pair of corresponding RADAR and FP data\n",
    "# Split the pairs into train and test sets\n",
    "train_pairs, test_pairs = train_test_split(data_pairs, test_size=0.2, random_state=42)\n",
    "\n",
    "# If needed, you can further split or organize these pairs into train/test folders or arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m train_test_split\n\u001b[0;32m----> 4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m Model\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m \u001b[39mimport\u001b[39;00m Input, Conv3D, Flatten, Dense, LSTM, TimeDistributed, Reshape\n\u001b[1;32m      7\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate_model_for_cop_x\u001b[39m(input_shape, output_sequence_length):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "def create_model_for_cop_x(input_shape, output_sequence_length):\n",
    "    input_layer = Input(shape=input_shape)  # input_shape is (4, X, 23, 13) for the RADAR RDMs\n",
    "    \n",
    "    # Conv3D layers to extract spatial features from the RADAR data\n",
    "    x = Conv3D(filters=64, kernel_size=(3, 3, 3), activation='relu')(input_layer)\n",
    "    x = Conv3D(filters=32, kernel_size=(3, 3, 3), activation='relu')(x)\n",
    "    x = Flatten()(x)\n",
    "    \n",
    "    # Dense layer for feature reduction before LSTM\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    # Reshaping to make it compatible for LSTM layer\n",
    "    x = Reshape((output_sequence_length, -1))(x)\n",
    "    \n",
    "    # LSTM layer to capture temporal dynamics\n",
    "    x = LSTM(128, return_sequences=True)(x)\n",
    "    \n",
    "    # TimeDistributed layer to predict COP_X at each time step\n",
    "    output_layer = TimeDistributed(Dense(1, activation='linear'))(x)  # 1 for COP_X value\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    model.compile(optimizer='adam', loss='mse')  # Use Mean Squared Error for regression tasks\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming radar_data is your input RADAR RDMs with shape [num_samples, 4, X, 23, 13]\n",
    "# Assuming cop_x_data is your target COP_X data with shape [num_samples, X, 1]\n",
    "\n",
    "model = create_model_for_cop_x(input_shape=(4, X, 23, 13), output_sequence_length=X)  # X is the number of frames/time steps\n",
    "\n",
    "# Training the model\n",
    "model.fit(radar_data, cop_x_data, epochs=10, batch_size=32, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.7 ('radartreepose_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "328376d6b0fabe9c025bc20907c001b430f3b746c3e3fb21cb53bd3449095683"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
