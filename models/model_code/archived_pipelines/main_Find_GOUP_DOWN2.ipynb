{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import Resize\n",
    "import os\n",
    "import random\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 60  # Number of frames; adjust based on your data\n",
    "slide_step = 8  # Adjust for finer or coarser granularity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class RdmDataset(Dataset):\n",
    "    def __init__(self, root_dir, event_labels_df, window_size, train=True):\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        self.window_size = window_size\n",
    "        # Assuming 'event_labels_df' is a DataFrame with columns ['RADAR_capture', 'Start_Frame', 'frame_stable', 'frame_break', 'End_Frame']\n",
    "        self.event_labels_df = event_labels_df\n",
    "\n",
    "        folders = sorted([d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))])\n",
    "        print(folders)\n",
    "        split_idx = int(len(folders) * 0.8)  # 80-20 split for train-test\n",
    "        selected_folders = folders[:split_idx] if train else folders[split_idx:]\n",
    "        \n",
    "        for folder in selected_folders:\n",
    "            folder_path = os.path.join(root_dir, folder)\n",
    "            for file in os.listdir(folder_path):\n",
    "                if file.endswith('.npy'):\n",
    "                    rdm_data = np.load(os.path.join(folder_path, file))\n",
    "                    print(rdm_data.shape)\n",
    "                    if rdm_data.shape[1] != 23 or rdm_data.shape[2] != 13:\n",
    "                        continue\n",
    "                    print(file)\n",
    "                    capture_labels = self.event_labels_df[self.event_labels_df['RADAR_capture'] == file[:14]]\n",
    "                    for index, row in capture_labels.iterrows():\n",
    "                        # Create windows and labels based on 'Start_Frame' to 'frame_stable' for GOUP, and 'frame_break' to 'End_Frame' for DOWN\n",
    "                        self._create_windows_and_labels(rdm_data, row)\n",
    "\n",
    "    def _create_windows_and_labels(self, rdm_data, row):\n",
    "        # Generate windows for GOUP\n",
    "        for start in range(int(row['Start_Frame']), int(row['frame_stable']) - self.window_size + 1):\n",
    "            self.data.append(rdm_data[start:start+self.window_size, :, :])\n",
    "            self.labels.append(0)  # GOUP label\n",
    "\n",
    "        # Generate windows for DOWN\n",
    "        # Check if 'frame_break' is NaN before generating windows for DOWN\n",
    "        if not np.isnan(row['frame_break']):\n",
    "            # Generate windows for DOWN\n",
    "            for start in range(int(row['frame_break']), int(row['End_Frame']) - self.window_size + 1):\n",
    "                self.data.append(rdm_data[start:start+self.window_size, :, :])\n",
    "                self.labels.append(2)  # DOWN label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "    \n",
    "# Define the model\n",
    "class RdmClassifier(nn.Module):\n",
    "    def __init__(self, num_classes, hidden_size):\n",
    "        super(RdmClassifier, self).__init__()\n",
    "        # Define a simple CNN architecture\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1),  # Assuming RDMs have a single channel\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(),  # This will flatten the output of the convolutional layers\n",
    "        )\n",
    "        cnn_output_size = self._get_conv_output_size()\n",
    "\n",
    "        # Define the LSTM layer\n",
    "        self.lstm = nn.LSTM(cnn_output_size, hidden_size, batch_first=True)\n",
    "        \n",
    "        # Define the fully connected layer for classification\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        batch_size, seq_len, _, _ = x.size()\n",
    "        # Apply CNN to each RDM in the sequence\n",
    "        c_out = self.cnn(x.view(batch_size * seq_len, 1, *x.size()[-2:]))\n",
    "        \n",
    "        # Reshape for LSTM input\n",
    "        r_out = c_out.view(batch_size, seq_len, -1)\n",
    "        \n",
    "        # Pack the sequence for LSTM\n",
    "        packed_input = pack_padded_sequence(r_out, lengths, batch_first=True, enforce_sorted=False)\n",
    "        packed_output, (hidden, _) = self.lstm(packed_input)\n",
    "\n",
    "        # Use the last hidden state\n",
    "        out = self.fc(hidden[-1])\n",
    "        return out\n",
    "    \n",
    "    def _get_conv_output_size(self):\n",
    "        # We can create a dummy input to calculate the output size after the CNN layers\n",
    "        with torch.no_grad():\n",
    "            dummy_input = torch.zeros(1, 1, 23, 13)  # Replace with your RDM shape\n",
    "            dummy_output = self.cnn(dummy_input)\n",
    "            return dummy_output.size(-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['01', '02', '03', '04', '05', '08', '10', '12', '13', '14', '15', '16', '18', '22', '24']\n",
      "(1000, 23, 13)\n",
      "01_MNTRL_RR_V1_channel1.npy\n",
      "(1000, 23, 13)\n",
      "01_MNTRL_RR_V1_channel2.npy\n",
      "(1000, 23, 13)\n",
      "01_MNTRL_RR_V1_channel3.npy\n",
      "(1000, 23, 13)\n",
      "01_MNTRL_RR_V1_channel4.npy\n",
      "(1000, 23, 13)\n",
      "01_MNTRL_RR_V2_channel1.npy\n",
      "(1000, 23, 13)\n",
      "01_MNTRL_RR_V2_channel2.npy\n",
      "(1000, 23, 13)\n",
      "01_MNTRL_RR_V2_channel3.npy\n",
      "(1000, 23, 13)\n",
      "01_MNTRL_RR_V2_channel4.npy\n",
      "(1000, 23, 13)\n",
      "01_MNTRL_RR_V3_channel1.npy\n",
      "(1000, 23, 13)\n",
      "01_MNTRL_RR_V3_channel2.npy\n",
      "(1000, 23, 13)\n",
      "01_MNTRL_RR_V3_channel3.npy\n",
      "(1000, 23, 13)\n",
      "01_MNTRL_RR_V3_channel4.npy\n",
      "(1000, 23, 13)\n",
      "01_MNTRR_RR_V1_channel1.npy\n",
      "(1000, 23, 13)\n",
      "01_MNTRR_RR_V1_channel2.npy\n",
      "(1000, 23, 13)\n",
      "01_MNTRR_RR_V1_channel3.npy\n",
      "(1000, 23, 13)\n",
      "01_MNTRR_RR_V1_channel4.npy\n",
      "(1000, 23, 13)\n",
      "01_MNTRR_RR_V2_channel1.npy\n",
      "(1000, 23, 13)\n",
      "01_MNTRR_RR_V2_channel2.npy\n",
      "(1000, 23, 13)\n",
      "01_MNTRR_RR_V2_channel3.npy\n",
      "(1000, 23, 13)\n",
      "01_MNTRR_RR_V2_channel4.npy\n",
      "(1000, 23, 13)\n",
      "01_MNTRR_RR_V3_channel1.npy\n",
      "(1000, 23, 13)\n",
      "01_MNTRR_RR_V3_channel2.npy\n",
      "(1000, 23, 13)\n",
      "01_MNTRR_RR_V3_channel3.npy\n",
      "(1000, 23, 13)\n",
      "01_MNTRR_RR_V3_channel4.npy\n",
      "(1000, 23, 13)\n",
      "02_MNTRL_RR_V1_channel1.npy\n",
      "(1000, 23, 13)\n",
      "02_MNTRL_RR_V1_channel2.npy\n",
      "(1000, 23, 13)\n",
      "02_MNTRL_RR_V1_channel3.npy\n",
      "(1000, 23, 13)\n",
      "02_MNTRL_RR_V1_channel4.npy\n",
      "(1000, 23, 13)\n",
      "02_MNTRL_RR_V2_channel1.npy\n",
      "(1000, 23, 13)\n",
      "02_MNTRL_RR_V2_channel2.npy\n",
      "(1000, 23, 13)\n",
      "02_MNTRL_RR_V2_channel3.npy\n",
      "(1000, 23, 13)\n",
      "02_MNTRL_RR_V2_channel4.npy\n",
      "(1000, 23, 13)\n",
      "02_MNTRL_RR_V3_channel1.npy\n",
      "(1000, 23, 13)\n",
      "02_MNTRL_RR_V3_channel2.npy\n",
      "(1000, 23, 13)\n",
      "02_MNTRL_RR_V3_channel3.npy\n",
      "(1000, 23, 13)\n",
      "02_MNTRL_RR_V3_channel4.npy\n",
      "(1000, 23, 13)\n",
      "02_MNTRR_RR_V1_channel1.npy\n",
      "(1000, 23, 13)\n",
      "02_MNTRR_RR_V1_channel2.npy\n",
      "(1000, 23, 13)\n",
      "02_MNTRR_RR_V1_channel3.npy\n",
      "(1000, 23, 13)\n",
      "02_MNTRR_RR_V1_channel4.npy\n",
      "(1000, 23, 13)\n",
      "02_MNTRR_RR_V2_channel1.npy\n",
      "(1000, 23, 13)\n",
      "02_MNTRR_RR_V2_channel2.npy\n",
      "(1000, 23, 13)\n",
      "02_MNTRR_RR_V2_channel3.npy\n",
      "(1000, 23, 13)\n",
      "02_MNTRR_RR_V2_channel4.npy\n",
      "(1000, 23, 13)\n",
      "02_MNTRR_RR_V3_channel1.npy\n",
      "(1000, 23, 13)\n",
      "02_MNTRR_RR_V3_channel2.npy\n",
      "(1000, 23, 13)\n",
      "02_MNTRR_RR_V3_channel3.npy\n",
      "(1000, 23, 13)\n",
      "02_MNTRR_RR_V3_channel4.npy\n",
      "(1000, 23, 13)\n",
      "03_MNTRL_RR_V1_channel1.npy\n",
      "(1000, 23, 13)\n",
      "03_MNTRL_RR_V1_channel2.npy\n",
      "(1000, 23, 13)\n",
      "03_MNTRL_RR_V1_channel3.npy\n",
      "(1000, 23, 13)\n",
      "03_MNTRL_RR_V1_channel4.npy\n",
      "(1000, 23, 13)\n",
      "03_MNTRL_RR_V2_channel1.npy\n",
      "(1000, 23, 13)\n",
      "03_MNTRL_RR_V2_channel2.npy\n",
      "(1000, 23, 13)\n",
      "03_MNTRL_RR_V2_channel3.npy\n",
      "(1000, 23, 13)\n",
      "03_MNTRL_RR_V2_channel4.npy\n",
      "(1000, 23, 13)\n",
      "03_MNTRL_RR_V3_channel1.npy\n",
      "(1000, 23, 13)\n",
      "03_MNTRL_RR_V3_channel2.npy\n",
      "(1000, 23, 13)\n",
      "03_MNTRL_RR_V3_channel3.npy\n",
      "(1000, 23, 13)\n",
      "03_MNTRL_RR_V3_channel4.npy\n",
      "(1000, 23, 13)\n",
      "03_MNTRR_RR_V1_channel1.npy\n",
      "(1000, 23, 13)\n",
      "03_MNTRR_RR_V1_channel2.npy\n",
      "(1000, 23, 13)\n",
      "03_MNTRR_RR_V1_channel3.npy\n",
      "(1000, 23, 13)\n",
      "03_MNTRR_RR_V1_channel4.npy\n",
      "(1000, 23, 13)\n",
      "03_MNTRR_RR_V2_channel1.npy\n",
      "(1000, 23, 13)\n",
      "03_MNTRR_RR_V2_channel2.npy\n",
      "(1000, 23, 13)\n",
      "03_MNTRR_RR_V2_channel3.npy\n",
      "(1000, 23, 13)\n",
      "03_MNTRR_RR_V2_channel4.npy\n",
      "(1000, 23, 13)\n",
      "03_MNTRR_RR_V3_channel1.npy\n",
      "(1000, 23, 13)\n",
      "03_MNTRR_RR_V3_channel2.npy\n",
      "(1000, 23, 13)\n",
      "03_MNTRR_RR_V3_channel3.npy\n",
      "(1000, 23, 13)\n",
      "03_MNTRR_RR_V3_channel4.npy\n",
      "(1000, 23, 13)\n",
      "04_MNTRL_RR_V1_channel1.npy\n",
      "(1000, 23, 13)\n",
      "04_MNTRL_RR_V1_channel2.npy\n",
      "(1000, 23, 13)\n",
      "04_MNTRL_RR_V1_channel3.npy\n",
      "(1000, 23, 13)\n",
      "04_MNTRL_RR_V1_channel4.npy\n",
      "(1000, 23, 13)\n",
      "04_MNTRL_RR_V2_channel1.npy\n",
      "(1000, 23, 13)\n",
      "04_MNTRL_RR_V2_channel2.npy\n",
      "(1000, 23, 13)\n",
      "04_MNTRL_RR_V2_channel3.npy\n",
      "(1000, 23, 13)\n",
      "04_MNTRL_RR_V2_channel4.npy\n",
      "(1000, 23, 13)\n",
      "04_MNTRL_RR_V3_channel1.npy\n",
      "(1000, 23, 13)\n",
      "04_MNTRL_RR_V3_channel2.npy\n",
      "(1000, 23, 13)\n",
      "04_MNTRL_RR_V3_channel3.npy\n",
      "(1000, 23, 13)\n",
      "04_MNTRL_RR_V3_channel4.npy\n",
      "(1000, 23, 13)\n",
      "04_MNTRR_RR_V1_channel1.npy\n",
      "(1000, 23, 13)\n",
      "04_MNTRR_RR_V1_channel2.npy\n",
      "(1000, 23, 13)\n",
      "04_MNTRR_RR_V1_channel3.npy\n",
      "(1000, 23, 13)\n",
      "04_MNTRR_RR_V1_channel4.npy\n",
      "(1000, 23, 13)\n",
      "04_MNTRR_RR_V2_channel1.npy\n",
      "(1000, 23, 13)\n",
      "04_MNTRR_RR_V2_channel2.npy\n",
      "(1000, 23, 13)\n",
      "04_MNTRR_RR_V2_channel3.npy\n",
      "(1000, 23, 13)\n",
      "04_MNTRR_RR_V2_channel4.npy\n",
      "(1000, 23, 13)\n",
      "04_MNTRR_RR_V3_channel1.npy\n",
      "(1000, 23, 13)\n",
      "04_MNTRR_RR_V3_channel2.npy\n",
      "(1000, 23, 13)\n",
      "04_MNTRR_RR_V3_channel3.npy\n",
      "(1000, 23, 13)\n",
      "04_MNTRR_RR_V3_channel4.npy\n",
      "(1000, 23, 13)\n",
      "05_MNTRL_RR_V1_channel1.npy\n",
      "(1000, 23, 13)\n",
      "05_MNTRL_RR_V1_channel2.npy\n",
      "(1000, 23, 13)\n",
      "05_MNTRL_RR_V1_channel3.npy\n",
      "(1000, 23, 13)\n",
      "05_MNTRL_RR_V1_channel4.npy\n",
      "(1000, 23, 13)\n",
      "05_MNTRL_RR_V2_channel1.npy\n",
      "(1000, 23, 13)\n",
      "05_MNTRL_RR_V2_channel2.npy\n",
      "(1000, 23, 13)\n",
      "05_MNTRL_RR_V2_channel3.npy\n",
      "(1000, 23, 13)\n",
      "05_MNTRL_RR_V2_channel4.npy\n",
      "(1000, 23, 13)\n",
      "05_MNTRL_RR_V3_channel1.npy\n",
      "(1000, 23, 13)\n",
      "05_MNTRL_RR_V3_channel2.npy\n",
      "(1000, 23, 13)\n",
      "05_MNTRL_RR_V3_channel3.npy\n",
      "(1000, 23, 13)\n",
      "05_MNTRL_RR_V3_channel4.npy\n",
      "(1000, 23, 13)\n",
      "05_MNTRR_RR_V1_channel1.npy\n",
      "(1000, 23, 13)\n",
      "05_MNTRR_RR_V1_channel2.npy\n",
      "(1000, 23, 13)\n",
      "05_MNTRR_RR_V1_channel3.npy\n",
      "(1000, 23, 13)\n",
      "05_MNTRR_RR_V1_channel4.npy\n",
      "(1000, 23, 13)\n",
      "05_MNTRR_RR_V2_channel1.npy\n",
      "(1000, 23, 13)\n",
      "05_MNTRR_RR_V2_channel2.npy\n",
      "(1000, 23, 13)\n",
      "05_MNTRR_RR_V2_channel3.npy\n",
      "(1000, 23, 13)\n",
      "05_MNTRR_RR_V2_channel4.npy\n",
      "(1000, 23, 13)\n",
      "05_MNTRR_RR_V3_channel1.npy\n",
      "(1000, 23, 13)\n",
      "05_MNTRR_RR_V3_channel2.npy\n",
      "(1000, 23, 13)\n",
      "05_MNTRR_RR_V3_channel3.npy\n",
      "(1000, 23, 13)\n",
      "05_MNTRR_RR_V3_channel4.npy\n",
      "(1000, 23, 13)\n",
      "08_MNTRL_RR_V1_channel1.npy\n",
      "(1000, 23, 13)\n",
      "08_MNTRL_RR_V1_channel2.npy\n",
      "(1000, 23, 13)\n",
      "08_MNTRL_RR_V1_channel3.npy\n",
      "(1000, 23, 13)\n",
      "08_MNTRL_RR_V1_channel4.npy\n",
      "(1000, 23, 13)\n",
      "08_MNTRL_RR_V2_channel1.npy\n",
      "(1000, 23, 13)\n",
      "08_MNTRL_RR_V2_channel2.npy\n",
      "(1000, 23, 13)\n",
      "08_MNTRL_RR_V2_channel3.npy\n",
      "(1000, 23, 13)\n",
      "08_MNTRL_RR_V2_channel4.npy\n",
      "(1000, 23, 13)\n",
      "08_MNTRL_RR_V3_channel1.npy\n",
      "(1000, 23, 13)\n",
      "08_MNTRL_RR_V3_channel2.npy\n",
      "(1000, 23, 13)\n",
      "08_MNTRL_RR_V3_channel3.npy\n",
      "(1000, 23, 13)\n",
      "08_MNTRL_RR_V3_channel4.npy\n",
      "(1000, 23, 13)\n",
      "08_MNTRR_RR_V1_channel1.npy\n",
      "(1000, 23, 13)\n",
      "08_MNTRR_RR_V1_channel2.npy\n",
      "(1000, 23, 13)\n",
      "08_MNTRR_RR_V1_channel3.npy\n",
      "(1000, 23, 13)\n",
      "08_MNTRR_RR_V1_channel4.npy\n",
      "(1000, 23, 13)\n",
      "08_MNTRR_RR_V2_channel1.npy\n",
      "(1000, 23, 13)\n",
      "08_MNTRR_RR_V2_channel2.npy\n",
      "(1000, 23, 13)\n",
      "08_MNTRR_RR_V2_channel3.npy\n",
      "(1000, 23, 13)\n",
      "08_MNTRR_RR_V2_channel4.npy\n",
      "(1000, 23, 13)\n",
      "08_MNTRR_RR_V3_channel1.npy\n",
      "(1000, 23, 13)\n",
      "08_MNTRR_RR_V3_channel2.npy\n",
      "(1000, 23, 13)\n",
      "08_MNTRR_RR_V3_channel3.npy\n",
      "(1000, 23, 13)\n",
      "08_MNTRR_RR_V3_channel4.npy\n",
      "(1000, 23, 13)\n",
      "10_MNTRL_RR_V1_channel1.npy\n",
      "(1000, 23, 13)\n",
      "10_MNTRL_RR_V1_channel2.npy\n",
      "(1000, 23, 13)\n",
      "10_MNTRL_RR_V1_channel3.npy\n",
      "(1000, 23, 13)\n",
      "10_MNTRL_RR_V1_channel4.npy\n",
      "(1000, 23, 13)\n",
      "10_MNTRL_RR_V2_channel1.npy\n",
      "(1000, 23, 13)\n",
      "10_MNTRL_RR_V2_channel2.npy\n",
      "(1000, 23, 13)\n",
      "10_MNTRL_RR_V2_channel3.npy\n",
      "(1000, 23, 13)\n",
      "10_MNTRL_RR_V2_channel4.npy\n",
      "(1000, 23, 13)\n",
      "10_MNTRL_RR_V3_channel1.npy\n",
      "(1000, 23, 13)\n",
      "10_MNTRL_RR_V3_channel2.npy\n",
      "(1000, 23, 13)\n",
      "10_MNTRL_RR_V3_channel3.npy\n",
      "(1000, 23, 13)\n",
      "10_MNTRL_RR_V3_channel4.npy\n",
      "(1000, 23, 13)\n",
      "10_MNTRR_RR_V1_channel1.npy\n",
      "(1000, 23, 13)\n",
      "10_MNTRR_RR_V1_channel2.npy\n",
      "(1000, 23, 13)\n",
      "10_MNTRR_RR_V1_channel3.npy\n",
      "(1000, 23, 13)\n",
      "10_MNTRR_RR_V1_channel4.npy\n",
      "(1000, 23, 13)\n",
      "10_MNTRR_RR_V2_channel1.npy\n",
      "(1000, 23, 13)\n",
      "10_MNTRR_RR_V2_channel2.npy\n",
      "(1000, 23, 13)\n",
      "10_MNTRR_RR_V2_channel3.npy\n",
      "(1000, 23, 13)\n",
      "10_MNTRR_RR_V2_channel4.npy\n",
      "(1000, 23, 13)\n",
      "10_MNTRR_RR_V3_channel1.npy\n",
      "(1000, 23, 13)\n",
      "10_MNTRR_RR_V3_channel2.npy\n",
      "(1000, 23, 13)\n",
      "10_MNTRR_RR_V3_channel3.npy\n",
      "(1000, 23, 13)\n",
      "10_MNTRR_RR_V3_channel4.npy\n",
      "(1000, 23, 13)\n",
      "12_MNTRL_RR_V2_channel1.npy\n",
      "(1000, 23, 13)\n",
      "12_MNTRL_RR_V2_channel2.npy\n",
      "(1000, 23, 13)\n",
      "12_MNTRL_RR_V2_channel3.npy\n",
      "(1000, 23, 13)\n",
      "12_MNTRL_RR_V2_channel4.npy\n",
      "(1000, 23, 13)\n",
      "12_MNTRL_RR_V3_channel1.npy\n",
      "(1000, 23, 13)\n",
      "12_MNTRL_RR_V3_channel2.npy\n",
      "(1000, 23, 13)\n",
      "12_MNTRL_RR_V3_channel3.npy\n",
      "(1000, 23, 13)\n",
      "12_MNTRL_RR_V3_channel4.npy\n",
      "(1000, 23, 13)\n",
      "12_MNTRR_RR_V1_channel1.npy\n",
      "(1000, 23, 13)\n",
      "12_MNTRR_RR_V1_channel2.npy\n",
      "(1000, 23, 13)\n",
      "12_MNTRR_RR_V1_channel3.npy\n",
      "(1000, 23, 13)\n",
      "12_MNTRR_RR_V1_channel4.npy\n",
      "(1000, 23, 13)\n",
      "12_MNTRR_RR_V2_channel1.npy\n",
      "(1000, 23, 13)\n",
      "12_MNTRR_RR_V2_channel2.npy\n",
      "(1000, 23, 13)\n",
      "12_MNTRR_RR_V2_channel3.npy\n",
      "(1000, 23, 13)\n",
      "12_MNTRR_RR_V2_channel4.npy\n",
      "(1000, 23, 13)\n",
      "12_MNTRR_RR_V3_channel1.npy\n",
      "(1000, 23, 13)\n",
      "12_MNTRR_RR_V3_channel2.npy\n",
      "(1000, 23, 13)\n",
      "12_MNTRR_RR_V3_channel3.npy\n",
      "(1000, 23, 13)\n",
      "12_MNTRR_RR_V3_channel4.npy\n",
      "(1000, 23, 13)\n",
      "13_MNTRL_RR_V1_channel1.npy\n",
      "(1000, 23, 13)\n",
      "13_MNTRL_RR_V1_channel2.npy\n",
      "(1000, 23, 13)\n",
      "13_MNTRL_RR_V1_channel3.npy\n",
      "(1000, 23, 13)\n",
      "13_MNTRL_RR_V1_channel4.npy\n",
      "(1000, 23, 13)\n",
      "13_MNTRL_RR_V2_channel1.npy\n",
      "(1000, 23, 13)\n",
      "13_MNTRL_RR_V2_channel2.npy\n",
      "(1000, 23, 13)\n",
      "13_MNTRL_RR_V2_channel3.npy\n",
      "(1000, 23, 13)\n",
      "13_MNTRL_RR_V2_channel4.npy\n",
      "(1000, 23, 13)\n",
      "13_MNTRL_RR_V3_channel1.npy\n",
      "(1000, 23, 13)\n",
      "13_MNTRL_RR_V3_channel2.npy\n",
      "(1000, 23, 13)\n",
      "13_MNTRL_RR_V3_channel3.npy\n",
      "(1000, 23, 13)\n",
      "13_MNTRL_RR_V3_channel4.npy\n",
      "(1000, 23, 13)\n",
      "13_MNTRR_RR_V1_channel1.npy\n",
      "(1000, 23, 13)\n",
      "13_MNTRR_RR_V1_channel2.npy\n",
      "(1000, 23, 13)\n",
      "13_MNTRR_RR_V1_channel3.npy\n",
      "(1000, 23, 13)\n",
      "13_MNTRR_RR_V1_channel4.npy\n",
      "(1000, 23, 13)\n",
      "13_MNTRR_RR_V2_channel1.npy\n",
      "(1000, 23, 13)\n",
      "13_MNTRR_RR_V2_channel2.npy\n",
      "(1000, 23, 13)\n",
      "13_MNTRR_RR_V2_channel3.npy\n",
      "(1000, 23, 13)\n",
      "13_MNTRR_RR_V2_channel4.npy\n",
      "(1000, 23, 13)\n",
      "13_MNTRR_RR_V3_channel1.npy\n",
      "(1000, 23, 13)\n",
      "13_MNTRR_RR_V3_channel2.npy\n",
      "(1000, 23, 13)\n",
      "13_MNTRR_RR_V3_channel3.npy\n",
      "(1000, 23, 13)\n",
      "13_MNTRR_RR_V3_channel4.npy\n",
      "(1000, 23, 13)\n",
      "14_MNTRL_RR_V1_channel1.npy\n",
      "(1000, 23, 13)\n",
      "14_MNTRL_RR_V1_channel2.npy\n",
      "(1000, 23, 13)\n",
      "14_MNTRL_RR_V1_channel3.npy\n",
      "(1000, 23, 13)\n",
      "14_MNTRL_RR_V1_channel4.npy\n",
      "(1000, 23, 13)\n",
      "14_MNTRL_RR_V2_channel1.npy\n",
      "(1000, 23, 13)\n",
      "14_MNTRL_RR_V2_channel2.npy\n",
      "(1000, 23, 13)\n",
      "14_MNTRL_RR_V2_channel3.npy\n",
      "(1000, 23, 13)\n",
      "14_MNTRL_RR_V2_channel4.npy\n",
      "(1000, 23, 13)\n",
      "14_MNTRL_RR_V3_channel1.npy\n",
      "(1000, 23, 13)\n",
      "14_MNTRL_RR_V3_channel2.npy\n",
      "(1000, 23, 13)\n",
      "14_MNTRL_RR_V3_channel3.npy\n",
      "(1000, 23, 13)\n",
      "14_MNTRL_RR_V3_channel4.npy\n",
      "(1000, 23, 13)\n",
      "14_MNTRR_RR_V1_channel1.npy\n",
      "(1000, 23, 13)\n",
      "14_MNTRR_RR_V1_channel2.npy\n",
      "(1000, 23, 13)\n",
      "14_MNTRR_RR_V1_channel3.npy\n",
      "(1000, 23, 13)\n",
      "14_MNTRR_RR_V1_channel4.npy\n",
      "(1000, 23, 13)\n",
      "14_MNTRR_RR_V2_channel1.npy\n",
      "(1000, 23, 13)\n",
      "14_MNTRR_RR_V2_channel2.npy\n",
      "(1000, 23, 13)\n",
      "14_MNTRR_RR_V2_channel3.npy\n",
      "(1000, 23, 13)\n",
      "14_MNTRR_RR_V2_channel4.npy\n",
      "(1000, 23, 13)\n",
      "14_MNTRR_RR_V3_channel1.npy\n",
      "(1000, 23, 13)\n",
      "14_MNTRR_RR_V3_channel2.npy\n",
      "(1000, 23, 13)\n",
      "14_MNTRR_RR_V3_channel3.npy\n",
      "(1000, 23, 13)\n",
      "14_MNTRR_RR_V3_channel4.npy\n",
      "(1000, 23, 13)\n",
      "15_MNTRL_RR_V1_channel1.npy\n",
      "(1000, 23, 13)\n",
      "15_MNTRL_RR_V1_channel2.npy\n",
      "(1000, 23, 13)\n",
      "15_MNTRL_RR_V1_channel3.npy\n",
      "(1000, 23, 13)\n",
      "15_MNTRL_RR_V1_channel4.npy\n",
      "(1000, 23, 13)\n",
      "15_MNTRL_RR_V2_channel1.npy\n",
      "(1000, 23, 13)\n",
      "15_MNTRL_RR_V2_channel2.npy\n",
      "(1000, 23, 13)\n",
      "15_MNTRL_RR_V2_channel3.npy\n",
      "(1000, 23, 13)\n",
      "15_MNTRL_RR_V2_channel4.npy\n",
      "(1000, 23, 13)\n",
      "15_MNTRL_RR_V3_channel1.npy\n",
      "(1000, 23, 13)\n",
      "15_MNTRL_RR_V3_channel2.npy\n",
      "(1000, 23, 13)\n",
      "15_MNTRL_RR_V3_channel3.npy\n",
      "(1000, 23, 13)\n",
      "15_MNTRL_RR_V3_channel4.npy\n",
      "(1000, 23, 13)\n",
      "15_MNTRR_RR_V1_channel1.npy\n",
      "(1000, 23, 13)\n",
      "15_MNTRR_RR_V1_channel2.npy\n",
      "(1000, 23, 13)\n",
      "15_MNTRR_RR_V1_channel3.npy\n",
      "(1000, 23, 13)\n",
      "15_MNTRR_RR_V1_channel4.npy\n",
      "(1000, 23, 13)\n",
      "15_MNTRR_RR_V2_channel1.npy\n",
      "(1000, 23, 13)\n",
      "15_MNTRR_RR_V2_channel2.npy\n",
      "(1000, 23, 13)\n",
      "15_MNTRR_RR_V2_channel3.npy\n",
      "(1000, 23, 13)\n",
      "15_MNTRR_RR_V2_channel4.npy\n",
      "(1000, 23, 13)\n",
      "15_MNTRR_RR_V3_channel1.npy\n",
      "(1000, 23, 13)\n",
      "15_MNTRR_RR_V3_channel2.npy\n",
      "(1000, 23, 13)\n",
      "15_MNTRR_RR_V3_channel3.npy\n",
      "(1000, 23, 13)\n",
      "15_MNTRR_RR_V3_channel4.npy\n",
      "(1000, 23, 13)\n",
      "16_MNTRL_RR_V1_channel1.npy\n",
      "(1000, 23, 13)\n",
      "16_MNTRL_RR_V1_channel2.npy\n",
      "(1000, 23, 13)\n",
      "16_MNTRL_RR_V1_channel3.npy\n",
      "(1000, 23, 13)\n",
      "16_MNTRL_RR_V1_channel4.npy\n",
      "(1000, 23, 13)\n",
      "16_MNTRL_RR_V2_channel1.npy\n",
      "(1000, 23, 13)\n",
      "16_MNTRL_RR_V2_channel2.npy\n",
      "(1000, 23, 13)\n",
      "16_MNTRL_RR_V2_channel3.npy\n",
      "(1000, 23, 13)\n",
      "16_MNTRL_RR_V2_channel4.npy\n",
      "(1000, 23, 13)\n",
      "16_MNTRL_RR_V3_channel1.npy\n",
      "(1000, 23, 13)\n",
      "16_MNTRL_RR_V3_channel2.npy\n",
      "(1000, 23, 13)\n",
      "16_MNTRL_RR_V3_channel3.npy\n",
      "(1000, 23, 13)\n",
      "16_MNTRL_RR_V3_channel4.npy\n",
      "(1000, 23, 13)\n",
      "16_MNTRR_RR_V1_channel1.npy\n",
      "(1000, 23, 13)\n",
      "16_MNTRR_RR_V1_channel2.npy\n",
      "(1000, 23, 13)\n",
      "16_MNTRR_RR_V1_channel3.npy\n",
      "(1000, 23, 13)\n",
      "16_MNTRR_RR_V1_channel4.npy\n",
      "(1000, 23, 13)\n",
      "16_MNTRR_RR_V2_channel1.npy\n",
      "(1000, 23, 13)\n",
      "16_MNTRR_RR_V2_channel2.npy\n",
      "(1000, 23, 13)\n",
      "16_MNTRR_RR_V2_channel3.npy\n",
      "(1000, 23, 13)\n",
      "16_MNTRR_RR_V2_channel4.npy\n",
      "(1000, 23, 13)\n",
      "16_MNTRR_RR_V3_channel1.npy\n",
      "(1000, 23, 13)\n",
      "16_MNTRR_RR_V3_channel2.npy\n",
      "(1000, 23, 13)\n",
      "16_MNTRR_RR_V3_channel3.npy\n",
      "(1000, 23, 13)\n",
      "16_MNTRR_RR_V3_channel4.npy\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "num_samples should be a positive integer value, but got num_samples=0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 29\u001b[0m\n\u001b[1;32m     26\u001b[0m train_dataset \u001b[39m=\u001b[39m RdmDataset(full_dataset_path, event_labels_df, window_size\u001b[39m=\u001b[39mwindow_size)\n\u001b[1;32m     28\u001b[0m \u001b[39m# Assuming 'train_dataset' is an instance of 'RdmDataset'\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m train_loader \u001b[39m=\u001b[39m DataLoader(train_dataset, batch_size\u001b[39m=\u001b[39;49m\u001b[39m4\u001b[39;49m, shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     31\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mNumber of samples in train_dataset:\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mlen\u001b[39m(train_dataset))\n\u001b[1;32m     33\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/radartreepose_env_new/lib/python3.8/site-packages/torch/utils/data/dataloader.py:350\u001b[0m, in \u001b[0;36mDataLoader.__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# map-style\u001b[39;00m\n\u001b[1;32m    349\u001b[0m     \u001b[39mif\u001b[39;00m shuffle:\n\u001b[0;32m--> 350\u001b[0m         sampler \u001b[39m=\u001b[39m RandomSampler(dataset, generator\u001b[39m=\u001b[39;49mgenerator)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    351\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    352\u001b[0m         sampler \u001b[39m=\u001b[39m SequentialSampler(dataset)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/radartreepose_env_new/lib/python3.8/site-packages/torch/utils/data/sampler.py:143\u001b[0m, in \u001b[0;36mRandomSampler.__init__\u001b[0;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mreplacement should be a boolean value, but got replacement=\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreplacement\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    142\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_samples, \u001b[39mint\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_samples \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 143\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mnum_samples should be a positive integer value, but got num_samples=\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_samples\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs=5):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for data, labels in train_loader:\n",
    "            data = data.float()  # Convert data to float\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(data, torch.tensor([data.size(1)]*len(data), dtype=torch.long))  # Ensure lengths tensor matches type\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(train_loader)}')\n",
    "\n",
    "# Example setup\n",
    "model = RdmClassifier(num_classes=3, hidden_size=128)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "event_labels_df = pd.read_csv('/Users/danielcopeland/Library/Mobile Documents/com~apple~CloudDocs/MIT Masters/DRL/LABx/RADARTreePose/data/csvs/MOCAP_FP_RADAR_FU_Stable_Break_FD_TIME_FRAMES.csv')\n",
    "\n",
    "full_dataset_path = \"/Volumes/FourTBLaCie/Yoga_Study_RADAR_1Ch\"\n",
    "train_dataset = RdmDataset(full_dataset_path, event_labels_df, window_size=window_size)\n",
    "\n",
    "# Assuming 'train_dataset' is an instance of 'RdmDataset'\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "print('Number of samples in train_dataset:', len(train_dataset))\n",
    "\n",
    "# Train the model\n",
    "train_model(model, train_loader, criterion, optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slide_and_predict(model, data, window_size, slide_step):\n",
    "    predictions = []\n",
    "    for start in range(0, len(data) - window_size + 1, slide_step):\n",
    "        end = start + window_size\n",
    "        window_data =  data[start:end]\n",
    "        prediction = model.predict(window_data)  # Adjust based on your model's prediction method\n",
    "        predictions.append((start, end, prediction))\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class RadarDataset(Dataset):\n",
    "    def __init__(self, segments, labels):\n",
    "        self.segments = segments  # Your preprocessed and segmented RADAR data\n",
    "        self.labels = labels  # Corresponding labels for each segment\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.segments)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.segments[idx], self.labels[idx]\n",
    "\n",
    "# Example usage\n",
    "dataset = RadarDataset(segments, labels)\n",
    "train_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpret_predictions(predictions, event_labels):\n",
    "    events_detected = []\n",
    "    for start, end, prediction in predictions:\n",
    "        if prediction == 'GOUP' and any((label['Start_Frame'] <= start < label['frame_stable']) or\n",
    "                                        (label['Start_Frame'] < end <= label['frame_stable']) for _, label in event_labels.iterrows()):\n",
    "            events_detected.append((start, end, 'GOUP'))\n",
    "        elif prediction == 'DOWN' and any((label['frame_break'] <= start < label['End_Frame']) or\n",
    "                                          (label['frame_break'] < end <= label['End_Frame']) for _, label in event_labels.iterrows()):\n",
    "            events_detected.append((start, end, 'DOWN'))\n",
    "    return events_detected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RdmClassifier' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m slide_step \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m  \u001b[39m# Example step size, adjust as needed\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[39m# Predict events\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m predictions \u001b[39m=\u001b[39m slide_and_predict(model, processed_data, window_size, slide_step)\n\u001b[1;32m     14\u001b[0m events_detected \u001b[39m=\u001b[39m interpret_predictions(predictions, event_labels)\n\u001b[1;32m     16\u001b[0m \u001b[39m# Do something with detected events\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[35], line 6\u001b[0m, in \u001b[0;36mslide_and_predict\u001b[0;34m(model, data, window_size, slide_step)\u001b[0m\n\u001b[1;32m      4\u001b[0m     end \u001b[39m=\u001b[39m start \u001b[39m+\u001b[39m window_size\n\u001b[1;32m      5\u001b[0m     window_data \u001b[39m=\u001b[39m  data[start:end]\n\u001b[0;32m----> 6\u001b[0m     prediction \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(window_data)  \u001b[39m# Adjust based on your model's prediction method\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     predictions\u001b[39m.\u001b[39mappend((start, end, prediction))\n\u001b[1;32m      8\u001b[0m \u001b[39mreturn\u001b[39;00m predictions\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/radartreepose_env_new/lib/python3.8/site-packages/torch/nn/modules/module.py:1688\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1686\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[1;32m   1687\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1688\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'RdmClassifier' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "# Assuming processed_data is loaded for each RADAR capture\n",
    "# Example for a single RADAR capture; loop or functionize for all captures as needed\n",
    "radar_capture_name = '01_MNTRL_RR_V1_Channel1'\n",
    "participant = radar_capture_name[:2]\n",
    "processed_data = np.load(f'/Volumes/FourTBLaCie/Yoga_Study_RADAR_1Ch/{participant}/{radar_capture_name}.npy')  # Adjust path as necessary\n",
    "event_labels = event_labels_df[event_labels_df['RADAR_capture'] == radar_capture_name[:14]]\n",
    "\n",
    "# Parameters for sliding window\n",
    "window_size = 100  # Example size, adjust as needed\n",
    "slide_step = 10  # Example step size, adjust as needed\n",
    "\n",
    "# Predict events\n",
    "predictions = slide_and_predict(model, processed_data, window_size, slide_step)\n",
    "events_detected = interpret_predictions(predictions, event_labels)\n",
    "\n",
    "# Do something with detected events\n",
    "for event in events_detected:\n",
    "    print(event)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.13 ('radartreepose_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "328376d6b0fabe9c025bc20907c001b430f3b746c3e3fb21cb53bd3449095683"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
