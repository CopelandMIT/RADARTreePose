{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Foot Up (FU) and Foot Down (FD) Preprocessing v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook loads processed radar data, labels frames based on foot up (FU) and foot down (FD) events, creates 100-frame windows, and saves the preprocessed data for model training.\n",
    "\n",
    "## Overview\n",
    "\n",
    "- **Load** processed radar data from the specified directory.\n",
    "- **Label** frames using event information from the metadata CSV file.\n",
    "- **Window** the data into 100-frame segments with overlap.\n",
    "- **Save** the preprocessed data for each participant.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: `load_participant_ids`\n",
    "\n",
    "This function retrieves unique participant IDs from the metadata CSV file by extracting the first two characters of the `RADAR_capture` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_participant_ids(metadata_csv):\n",
    "    \"\"\"\n",
    "    Get unique participant IDs from the metadata CSV file based on the first two characters of 'RADAR_capture'.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(metadata_csv)\n",
    "    participant_ids = df['RADAR_capture'].str[:2].unique()\n",
    "    return participant_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: `label_frames`\n",
    "\n",
    "This function assigns labels to frames based on event timings for a given radar capture.\n",
    "\n",
    "- **Label 0**: Foot Up (GOUP)\n",
    "- **Label 1**: Foot Down (DOWN)\n",
    "- **Label 2**: Stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_frames(event_labels_df, radar_capture, num_frames):\n",
    "    \"\"\"\n",
    "    Label frames based on event timings for the given radar capture.\n",
    "    \"\"\"\n",
    "    labels = np.full(num_frames, 2)  # Default to 'stability' label (2)\n",
    "\n",
    "    capture_events = event_labels_df[event_labels_df['RADAR_capture'] == radar_capture]\n",
    "    goup_ranges = []\n",
    "    down_ranges = []\n",
    "\n",
    "    for _, event in capture_events.iterrows():\n",
    "        if not pd.isna(event['frame_foot_up']) and not pd.isna(event['frame_stable']):\n",
    "            start = int(event['frame_foot_up'])\n",
    "            end = int(event['frame_stable'])\n",
    "            labels[start:end] = 0  # GOUP\n",
    "            goup_ranges.append((start, end))\n",
    "        if not pd.isna(event['frame_break']) and not pd.isna(event['frame_end']):\n",
    "            start = int(event['frame_break'])\n",
    "            end = int(event['frame_end'])\n",
    "            labels[start:end] = 1  # DOWN\n",
    "            down_ranges.append((start, end))\n",
    "\n",
    "    return labels, goup_ranges, down_ranges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: `create_windows`\n",
    "\n",
    "This function creates overlapping windows of data and applies the corresponding labels to each window.\n",
    "\n",
    "- **Parameters:**\n",
    "  - `data`: The processed radar data tensor.\n",
    "  - `labels`: The array of labels corresponding to each frame.\n",
    "  - `metadata`: A dictionary containing metadata for the capture.\n",
    "  - `window_size`: The size of each window (default is 100 frames).\n",
    "  - `overlap`: The number of frames that overlap between consecutive windows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_windows(data, labels, metadata, window_size=100, overlap=50):\n",
    "    \"\"\"\n",
    "    Create windows of data with specified overlap and apply labels.\n",
    "    \"\"\"\n",
    "    actuator_start_frame, actuator_end_frame = metadata['frame_range']\n",
    "    num_windows = 1 + (actuator_end_frame - actuator_start_frame - window_size) // (window_size - overlap)\n",
    "\n",
    "    windows_data = []\n",
    "    windows_labels = []\n",
    "    windows_ranges = []\n",
    "\n",
    "    for w in range(num_windows):\n",
    "        start = w * (window_size - overlap) + actuator_start_frame\n",
    "        end = start + window_size\n",
    "        window_range = {'window_start_frame': start, 'window_end_frame': min(end, actuator_end_frame)}\n",
    "\n",
    "        if end > actuator_end_frame:\n",
    "            padding_length = end - actuator_end_frame\n",
    "            window_data = torch.cat((data[start:actuator_end_frame], torch.zeros(padding_length, *data.shape[1:])), dim=0)\n",
    "            window_labels = np.pad(labels[start:actuator_end_frame], (0, padding_length), 'constant', constant_values=-1)\n",
    "        else:\n",
    "            window_data = data[start:end]\n",
    "            window_labels = labels[start:end]\n",
    "\n",
    "        windows_data.append(window_data.unsqueeze(0))\n",
    "        windows_labels.append(torch.tensor(window_labels).unsqueeze(0))\n",
    "        windows_ranges.append(window_range)\n",
    "\n",
    "    # Concatenate to tensors\n",
    "    windows_data_tensor = torch.cat(windows_data, dim=0)\n",
    "    windows_labels_tensor = torch.cat(windows_labels, dim=0)\n",
    "\n",
    "    return windows_data_tensor, windows_labels_tensor, windows_ranges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Preprocessing Function\n",
    "\n",
    "### Function: `preprocess_data`\n",
    "\n",
    "This function orchestrates the preprocessing steps:\n",
    "\n",
    "- Loads the metadata and participant IDs.\n",
    "- Iterates over each participant and their radar captures.\n",
    "- Loads processed radar data.\n",
    "- Labels frames.\n",
    "- Creates windows.\n",
    "- Saves the preprocessed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_data(root_dir, metadata_csv, output_dir, window_size=100, overlap=50):\n",
    "    \"\"\"\n",
    "    Main preprocessing function to load, label, window, and save data for each participant.\n",
    "    \"\"\"\n",
    "    # Load metadata\n",
    "    participant_ids = load_participant_ids(metadata_csv)\n",
    "    event_labels_df = pd.read_csv(metadata_csv)\n",
    "\n",
    "    # Process each participant's data\n",
    "    for participant_id in participant_ids:\n",
    "        participant_dir = os.path.join(root_dir, participant_id)\n",
    "        if not os.path.exists(participant_dir):\n",
    "            print(f\"Participant directory {participant_dir} does not exist. Skipping.\")\n",
    "            continue  # Skip if directory does not exist\n",
    "\n",
    "        for file in sorted(os.listdir(participant_dir)):\n",
    "            if file.endswith('.npy'):\n",
    "                filepath = os.path.join(participant_dir, file)\n",
    "                radar_capture = \"_\".join(file.split('_')[:-1])\n",
    "                channel_number = filepath.split(\".\")[-2].split(\"channel\")[-1]\n",
    "\n",
    "                if event_labels_df['RADAR_capture'].str.contains(radar_capture).any():\n",
    "                    data = torch.from_numpy(np.load(filepath)).float()\n",
    "\n",
    "                    # Get number of frames from data shape\n",
    "                    num_frames = data.shape[0]\n",
    "\n",
    "                    # Label frames for this capture\n",
    "                    labels, goup_ranges, down_ranges = label_frames(event_labels_df, radar_capture, num_frames)\n",
    "\n",
    "                    # Extract metadata\n",
    "                    capture_info = event_labels_df[event_labels_df['RADAR_capture'] == radar_capture].iloc[0]\n",
    "                    actuator_start_frame = int(capture_info['RADAR_Start_Frame'])\n",
    "                    actuator_end_frame = int(capture_info['RADAR_End_Frame'])\n",
    "                    metadata = {\n",
    "                        'channel_number': channel_number,\n",
    "                        'frame_range': (actuator_start_frame, actuator_end_frame),\n",
    "                        'RADAR_capture': radar_capture,\n",
    "                        'GOUP_ranges': goup_ranges,\n",
    "                        'DOWN_ranges': down_ranges\n",
    "                    }\n",
    "\n",
    "                    # Create windows\n",
    "                    windows_data, windows_labels, windows_ranges = create_windows(\n",
    "                        data, labels, metadata, window_size, overlap\n",
    "                    )\n",
    "\n",
    "                    # Save windows and metadata\n",
    "                    output_participant_dir = os.path.join(output_dir, participant_id)\n",
    "                    os.makedirs(output_participant_dir, exist_ok=True)\n",
    "                    output_file = os.path.join(output_participant_dir, f\"{radar_capture}_windows.pt\")\n",
    "                    torch.save({\n",
    "                        'data': windows_data,\n",
    "                        'labels': windows_labels,\n",
    "                        'ranges': windows_ranges,\n",
    "                        'metadata': metadata\n",
    "                    }, output_file)\n",
    "\n",
    "                    print(f\"Saved preprocessed data for {radar_capture} to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Preprocessing Pipeline\n",
    "\n",
    "Adjust the paths and parameters as needed to match your data directory structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths and parameters\n",
    "root_dir = \"/Volumes/FourTBLaCie/RADARTreePose_Data/processed/radar/RDMs_npy_by_channel_v1\"\n",
    "metadata_csv = \"/Volumes/FourTBLaCie/RADARTreePose_Data/metadata/FULL_MNTRR_MNTRL_key_times_frames.csv\"\n",
    "output_dir = \"/Volumes/FourTBLaCie/RADARTreePose_Data/preprocessed/radar\"\n",
    "window_size = 100\n",
    "overlap = 10  # Adjust overlap as needed\n",
    "\n",
    "# Run preprocessing\n",
    "preprocess_data(root_dir, metadata_csv, output_dir, window_size, overlap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "- **Data Assumptions:**\n",
    "  - The number of frames (`num_frames`) is determined from the shape of the loaded radar data.\n",
    "  - Radar captures are stored in `.npy` files within participant-specific directories.\n",
    "  - The metadata CSV contains event timing information necessary for labeling.\n",
    "\n",
    "- **Labels:**\n",
    "  - **Label 0**: Foot Up (GOUP)\n",
    "  - **Label 1**: Foot Down (DOWN)\n",
    "  - **Label 2**: Stability\n",
    "  - **Label -1**: Padding (used when windows extend beyond the capture's end frame)\n",
    "\n",
    "- **Saving Data:**\n",
    "  - Preprocessed data is saved as `.pt` files using PyTorch's `torch.save` function.\n",
    "  - Each participant has their own directory within the `output_dir`.\n",
    "\n",
    "---\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "This notebook processes the radar data by:\n",
    "\n",
    "1. Loading processed radar data for each participant.\n",
    "2. Labeling frames based on foot up/down events.\n",
    "3. Creating overlapping windows of data.\n",
    "4. Saving the preprocessed data for use in model training.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.13 ('radartreepose_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "328376d6b0fabe9c025bc20907c001b430f3b746c3e3fb21cb53bd3449095683"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
