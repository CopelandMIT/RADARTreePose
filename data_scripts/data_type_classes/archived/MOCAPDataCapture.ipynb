{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "import re\n",
    "from datetime import datetime\n",
    "from scipy.signal import find_peaks, convolve\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MOCAPDataCapture:\n",
    "    def __init__(self, base_file_path):\n",
    "        self.base_file_path = base_file_path\n",
    "        self.sample_frequency = 100\n",
    "        self.pos_file_path = base_file_path.replace(\".tsv\", \"_pos.tsv\")\n",
    "        self.vel_file_path = base_file_path.replace(\".tsv\", \"_vel.tsv\")\n",
    "        # Pattern to match \"/##/\" where ## are two digits\n",
    "        self.participant_pattern = r\"/(\\d{2})/\"\n",
    "        match = re.search(self.participant_pattern, base_file_path)\n",
    "        if match:\n",
    "            self.participant_id = match.group(1)\n",
    "            print(f\"Processing File: {self.base_file_path.split('/')[-1]}\")\n",
    "        else:\n",
    "            raise ValueError(\"Participant ID could not be extracted from the base file path.\")\n",
    "        self.position_data = None\n",
    "        self.velocity_data = None\n",
    "        self.start_actuator_time = None\n",
    "        self.end_actuator_time = None\n",
    "        self.load_and_process_data()\n",
    "\n",
    "    def load_and_process_data(self):\n",
    "        \"\"\"\n",
    "        Loads and processes position and velocity data from TSV files.\n",
    "\n",
    "        Args:\n",
    "            pos_file_path (str): The file path to the position TSV file.\n",
    "            vel_file_path (str): The file path to the velocity TSV file.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # self.position_data = self.process_tsv(self.pos_file_path)\n",
    "            self.velocity_data = self.process_tsv(self.vel_file_path)\n",
    "            # print(\"Position and velocity data loaded and processed.\")\n",
    "            # print(self.position_data)\n",
    "            # print(self.velocity_data)\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            \n",
    "    def Thirteen_MNTRL_V2(self):\n",
    "        return\n",
    "        \n",
    "    def process_tsv(self, file_path, save_to_csv=False):\n",
    "        print(file_path)\n",
    "        if not os.path.isfile(file_path):\n",
    "            raise FileNotFoundError(f\"The file '{file_path}' does not exist.\")\n",
    "        with open(file_path, mode='r', newline='') as tsv_file:\n",
    "            tsv_reader = csv.reader(tsv_file, delimiter='\\t')\n",
    "            # print(tsv_reader)\n",
    "            first_5_rows_list = []\n",
    "            remaining_rows_list = []\n",
    "\n",
    "            try:\n",
    "                for i, row in enumerate(tsv_reader):\n",
    "                    if i < 5:\n",
    "                        first_5_rows_list.append(row)\n",
    "                    else:\n",
    "                        if len(row) < 58:\n",
    "                            row += [''] * (58 - len(row))\n",
    "                        remaining_rows_list.append(row)\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred while processing the file: {e}\")\n",
    "                return\n",
    "\n",
    "\n",
    "            # Create Header pandas DataFrames from first 5 rows of lists\n",
    "            df_header = pd.DataFrame(first_5_rows_list).set_index(0)\n",
    "            try:\n",
    "                df_header.columns = [\"Value\"]\n",
    "            except:\n",
    "                pass\n",
    "            # print(\"Header for data frame\")\n",
    "            # print(df_header)\n",
    "            \n",
    "            # Create blank, correct shape pandas DataFrames from remainder of lists\n",
    "            df = pd.DataFrame(remaining_rows_list)\n",
    "            # print('New data frame')\n",
    "            \n",
    "            # Shift row 6 to the left and remove cell 6,1\n",
    "            df.iloc[2, 0:-1] = df.iloc[0, 1:].values\n",
    "            \n",
    "            #delete empty column\n",
    "            df = df.iloc[:,:-1]\n",
    "\n",
    "            # Remove rows 7 and 8 (originally 8 and 9)\n",
    "            df = df.drop(df.index[0:2])\n",
    "            df.columns = df.iloc[0]\n",
    "            df = df.drop(df.index[0])\n",
    "            # print('2: New data frame')\n",
    "            # print(df)\n",
    "            \n",
    "            ## Change data types of columns\n",
    "            df = df.apply(pd.to_numeric, downcast='float')\n",
    "            \n",
    "            # Add 'frame', 'time' and participant columns\n",
    "            df.insert(0, 'frame', range(0, len(df)))\n",
    "            df.insert(1, 'time', [i * 0.01 for i in range(len(df))])\n",
    "            df.insert(2,'participant_id', self.participant_id)\n",
    "            \n",
    "            # Reset index\n",
    "            df.reset_index(drop=True, inplace=True)\n",
    "                  \n",
    "            if save_to_csv == True:      \n",
    "                if df.shape[0] != 4000:\n",
    "                    print(df.shape)\n",
    "                    raise Exception(\"DATA Frame is the wrong size!!\")\n",
    "                else:\n",
    "                    self.output_folder = \"/Users/danielcopeland/Library/Mobile Documents/com~apple~CloudDocs/MIT Masters/DRL/LABx/RADARTreePose/data/csvs\"\n",
    "                    output_file_path = os.path.join(\n",
    "                        self.output_folder, os.path.splitext(os.path.basename(file_path))[0] + \".csv\"\n",
    "                    )\n",
    "                    print(f\"Saved: {os.path.basename(file_path)}\")\n",
    "                    df.to_csv(output_file_path, index=False, header=True)\n",
    "            return df\n",
    "    \n",
    "    \n",
    "    def plot_convolution_result(self, actuator_vel_x):\n",
    "        \"\"\"\n",
    "        Plots the convolution result along with a threshold line to help determine an appropriate threshold.\n",
    "\n",
    "        Args:\n",
    "            actuator_vel_x (np.array): The actuator velocity data.\n",
    "        \"\"\"\n",
    "        # Generate the template signal\n",
    "        template = np.concatenate([np.full(102, 50), np.zeros(10), np.full(102, -50)])\n",
    "\n",
    "        # Convolve the template with the actuator velocity data\n",
    "        convolution_result = convolve(actuator_vel_x, template, mode='valid')\n",
    "\n",
    "        # Find local minima in the convolution result\n",
    "        local_minima_indices, _ = find_peaks(-convolution_result)\n",
    "\n",
    "        # Define the threshold\n",
    "        threshold = -4e5\n",
    "\n",
    "        # Plot the convolution result\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(convolution_result, label='Convolution Result')\n",
    "        \n",
    "        # Plot the local minima\n",
    "        plt.plot(local_minima_indices, convolution_result[local_minima_indices], 'rx', label='Local Minima')\n",
    "\n",
    "        # Plot the threshold line\n",
    "        plt.axhline(y=threshold, color='g', linestyle='--', label=f'Threshold ({threshold})')\n",
    "\n",
    "        plt.xlabel('Time Step')\n",
    "        plt.ylabel('Convolution Value')\n",
    "        plt.title('Convolution Result with Local Minima and Threshold')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "\n",
    "    def find_actuator_start_end_direction_changes(self):\n",
    "        \"\"\"\n",
    "        Uses convolution to find the start and end times of transitions in the actuator velocity \n",
    "        from around +50 to -50, ensuring that peaks are not within 2 seconds of each other.\n",
    "        \"\"\"\n",
    "        if self.velocity_data is None:\n",
    "            print(\"Velocity data not loaded. Please load data before running this function.\")\n",
    "            return\n",
    "\n",
    "        # Generate the template signal\n",
    "        template = np.concatenate([np.full(102, 50), np.zeros(10), np.full(102, -50)])\n",
    "\n",
    "        # Extract the actuator X velocity data\n",
    "        actuator_vel_x = self.velocity_data['Actuator_vel_X'].to_numpy()\n",
    "\n",
    "        # Convolve the template with the actuator velocity data\n",
    "        convolution_result = convolve(actuator_vel_x, template, mode='valid')\n",
    "\n",
    "        # Find local minima in the convolution result as potential matches\n",
    "        local_minima_indices, _ = find_peaks(-convolution_result)\n",
    "\n",
    "        # Threshold for determining a strong match\n",
    "        threshold = -4e5  # Adjust based on your data's characteristics\n",
    "\n",
    "        # Filter out matches that don't meet the threshold\n",
    "        significant_matches = [idx for idx in local_minima_indices if convolution_result[idx] < threshold]\n",
    "\n",
    "        # Ensure matches are not within 200 indices of each other\n",
    "        filtered_matches = []\n",
    "        for match in significant_matches:\n",
    "            if not filtered_matches:  # If list is empty, add the first match\n",
    "                filtered_matches.append(match)\n",
    "            else:\n",
    "                # Check if current match is more than 200 indices apart from the last added match\n",
    "                if match - filtered_matches[-1] > 200:\n",
    "                    filtered_matches.append(match)\n",
    "                else:\n",
    "                    # If within 200 indices, keep the one with the more significant peak (lower value in convolution result)\n",
    "                    if convolution_result[match] < convolution_result[filtered_matches[-1]]:\n",
    "                        filtered_matches[-1] = match  # Replace the last match with the current one\n",
    "\n",
    "        if filtered_matches:\n",
    "            # Set start and end times based on the filtered matches\n",
    "            self.start_actuator_time = self.velocity_data.iloc[filtered_matches[0]]['time']\n",
    "            if len(filtered_matches) > 1:\n",
    "                self.end_actuator_time = self.velocity_data.iloc[filtered_matches[1]]['time']\n",
    "            print(f\"Start actuator time: {self.start_actuator_time}, End actuator time: {self.end_actuator_time}\")\n",
    "        else:\n",
    "            print(\"No appropriate transitions found in the Actuator_vel_X data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.7 ('radartreepose_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "328376d6b0fabe9c025bc20907c001b430f3b746c3e3fb21cb53bd3449095683"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
