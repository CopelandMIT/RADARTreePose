{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class FPDataCapture:\n",
    "    def __init__(self, base_file_path):\n",
    "        self.headers_f_1 = {}\n",
    "        self.headers_f_2 = {}\n",
    "        self.sample_frequency = 1200\n",
    "        self.base_file_path = base_file_path\n",
    "        self.data_f_1 = self.import_data(self.base_file_path.replace(\".tsv\", \"_f_1.tsv\"), self.headers_f_1)\n",
    "        self.data_f_2 = self.import_data(self.base_file_path.replace(\".tsv\", \"_f_2.tsv\"), self.headers_f_2)\n",
    "        self.foot_lift_times = None\n",
    "        self.foot_down_times = None\n",
    "\n",
    "    def import_data(self, file_path, headers_dict):\n",
    "        # The number of initial lines containing metadata information.\n",
    "        num_metadata_lines = 26 \n",
    "        \n",
    "        # Assuming that the first line of actual data has the correct column headers\n",
    "        data = pd.read_csv(file_path, delimiter='\\t', header=num_metadata_lines)\n",
    "        \n",
    "        # Convert data to numeric, handling non-numeric entries\n",
    "        data = data.apply(pd.to_numeric, errors='coerce')\n",
    "        \n",
    "        # Change TIME to time\n",
    "        data.rename(columns={\"TIME\": \"time\"}, inplace=True)\n",
    "\n",
    "        # Reset the index and column names of the dataframe\n",
    "        data.reset_index(drop=False, inplace=True)\n",
    "        column_names = list(data.columns)[1:]\n",
    "        data.drop(data.columns[-1], axis=1, inplace=True)\n",
    "        data.columns = column_names\n",
    "        \n",
    "        test_file_path = \"/Users/danielcopeland/Library/Mobile Documents/com~apple~CloudDocs/MIT Masters/DRL/LABx/RADARTreePose/data/csvs/\"\n",
    "         \n",
    "        # Save the DataFrame to a CSV file\n",
    "        csv_file_path = test_file_path + str(file_path.split('/')[-1].replace('.tsv', '.csv'))\n",
    "        data.to_csv(csv_file_path, index=False)\n",
    "        print(f\"Data saved to {csv_file_path}\")\n",
    "\n",
    "        return data\n",
    "\n",
    "    def identify_foot_lift(self):\n",
    "        # Determine which force plate data to use based on the filename content\n",
    "        if \"MNTRL\" in self.base_file_path:\n",
    "            data = self.data_f_1\n",
    "        elif \"MNTRR\" in self.base_file_path:\n",
    "            data = self.data_f_2\n",
    "        else:\n",
    "            raise ValueError(\"Filename must contain 'MNTRL' or 'MNTRR'\")\n",
    "        \n",
    "        # Convert 'time' column to numeric for comparison\n",
    "        data['time'] = pd.to_numeric(data['time'], errors='coerce')\n",
    "\n",
    "        # Identifying foot lift and put down events\n",
    "        # A foot lift event is identified when COP_X and COP_Y go from non-zero to zero\n",
    "        foot_lift_events = data[(data['COP_X'].shift(1) != 0) & (data['COP_Y'].shift(1) != 0) &\n",
    "                                (data['COP_X'] == 0) & (data['COP_Y'] == 0)]\n",
    "\n",
    "        # A foot down event is identified when COP_X and COP_Y go from zero to non-zero\n",
    "        foot_down_events = data[(data['COP_X'].shift(1) == 0) & (data['COP_Y'].shift(1) == 0) &\n",
    "                                (data['COP_X'] != 0) & (data['COP_Y'] != 0)]\n",
    "\n",
    "        # Filter out foot lift events that are too close to each other (within 0.1 seconds)\n",
    "        filtered_lift_times = []\n",
    "        for t in data.loc[foot_lift_events.index, 'time']:\n",
    "            if not filtered_lift_times or t - filtered_lift_times[-1] > 0.1:\n",
    "                filtered_lift_times.append(t)\n",
    "\n",
    "        # Filter out foot down events that are too close to foot lift events\n",
    "        filtered_down_times = []\n",
    "        for t in data.loc[foot_down_events.index, 'time']:\n",
    "            if not any(abs(t - lift_time) <= 0.1 for lift_time in filtered_lift_times):\n",
    "                filtered_down_times.append(t)\n",
    "\n",
    "        # Now filter foot down events that are too close to each other (within 0.1 seconds)\n",
    "        final_filtered_down_times = []\n",
    "        for t in filtered_down_times:\n",
    "            if not final_filtered_down_times or t - final_filtered_down_times[-1] > 0.1:\n",
    "                final_filtered_down_times.append(t)\n",
    "\n",
    "        # Save the times for foot lift and put down events\n",
    "        self.foot_lift_times = filtered_lift_times\n",
    "        self.foot_down_times = final_filtered_down_times\n",
    "\n",
    "        # Returning the times where foot lift and put down events occur\n",
    "        return self.foot_lift_times, self.foot_down_times\n",
    "\n",
    "# Usage example:\n",
    "# file_path_f_1 = 'path_to_f_1.tsv' # Replace with actual file path\n",
    "# file_path_f_2 = 'path_to_f_2.tsv' # Replace with actual file path\n",
    "# fp_data_capture = FPDataCapture(file_path_f_1, file_path_f_2)\n",
    "# filename_to_check = 'some_filename_containing_MNTRL_or_MNTRR'\n",
    "# fp_data_capture.identify_foot_lift(filename_to_check)\n",
    "# Now you can access the times directly\n",
    "# print(fp_data_capture.foot_lift_times_f_1)\n",
    "# print(fp_data_capture.foot_down_times_f_1)\n",
    "# print(fp_data_capture.foot_lift_times_f_2)\n",
    "# print(fp_data_capture.foot_down_times_f_2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.7 ('radartreepose_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "328376d6b0fabe9c025bc20907c001b430f3b746c3e3fb21cb53bd3449095683"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
